{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Load and clean the flight data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/rk/815pd2rj3l5gyxnkn8q_m5sc0000gn/T/ipykernel_4331/3466897392.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'.csv'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data1'"
     ]
    }
   ],
   "source": [
    "# Get a list of dataframes for each CSV file in the data subfolder\n",
    "\n",
    "data = []\n",
    "\n",
    "for x in os.listdir('data1'):\n",
    "    if '.csv' not in x:\n",
    "        continue\n",
    "    print(x)\n",
    "    data.append(pd.read_csv(f'data1/{x}',encoding='unicode_escape',low_memory=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the list of dataframes into one, on columns\n",
    "data = pd.concat(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-index the dataframe, since there are multiple rows with the same index number because it was concatenated from multiple dataframes\n",
    "data.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace date string data with actual datetime data\n",
    "dates = pd.to_datetime(data.fl_date)\n",
    "years = dates.dt.year\n",
    "julian_dates = dates.dt.day_of_year\n",
    "data['year'] = years\n",
    "data['julian'] = julian_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to take an integer representing 24 hour time and convert it to a minute-of-the-day integer; front-end zero-padding needed\n",
    "\n",
    "def hhmm_to_minutes(hhmm):\n",
    "    hhmm = str(hhmm)\n",
    "    hhmm = hhmm.split('.')[0]\n",
    "    if len(hhmm) < 4:\n",
    "        hhmm = '0' * (4-len(hhmm)) + hhmm\n",
    "    hh = int(hhmm[:2]) * 60\n",
    "    mm = int(hhmm[2:])\n",
    "    hhmm = hh+mm\n",
    "    return hhmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_relevant = data[['year','julian','mkt_unique_carrier','mkt_carrier_fl_num','op_unique_carrier','op_carrier_fl_num','origin_airport_id','origin','dest_airport_id',\n",
    "                      'dest','distance','crs_arr_time','arr_time','crs_dep_time','dep_time','crs_elapsed_time','actual_elapsed_time','dep_delay','arr_delay']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove NaN values now that the NaN-heavy columns are gone\n",
    "data_relevant = data_relevant.dropna()\n",
    "\n",
    "# Convert columns with time in hhmm integers to minute-of-the-day values\n",
    "for col in ['crs_dep_time','dep_time','crs_arr_time','arr_time']:\n",
    "    print(col)\n",
    "    data_relevant[col] = data_relevant[col].apply(hhmm_to_minutes)\n",
    "\n",
    "# Calculate in-air delay time and the difference between CRS and actual elapsed time\n",
    "data_relevant['in_air_delay'] = data_relevant.arr_delay - data_relevant.dep_delay\n",
    "data_relevant['act_minus_crs'] = data_relevant.actual_elapsed_time - data_relevant.crs_elapsed_time\n",
    "\n",
    "# Remove rows where in-air delay and actual minus CRS elapsed time differ, as these must be errors of some kind\n",
    "data_relevant = data_relevant[data_relevant.in_air_delay == data_relevant.act_minus_crs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the relevant, cleaned data\n",
    "data_relevant.to_csv('All_Flight_Data_Cleaned.csv.gz',compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Selecting training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_relevant = pd.read_csv('All_Flight_Data_Cleaned.csv.gz',compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get three categories of data -- on time (within 5 minutes of scheduled arrival), 15-30 min delay, 60+ min delay\n",
    "ontime = data_relevant[np.abs(data_relevant.arr_delay) <= 5]\n",
    "delayed_15 = data_relevant[(data_relevant.arr_delay >= 15) & (data_relevant.arr_delay <= 30)]\n",
    "delayed_60 = data_relevant[data_relevant.arr_delay >= 60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All three categories have at least one million entries, so sample one million from each:\n",
    "ontime = ontime.sample(1000000)\n",
    "delayed_15 = delayed_15.sample(1000000)\n",
    "delayed_60 = delayed_60.sample(1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "ontime['cat_ontime'] = np.ones(len(ontime))\n",
    "ontime['cat_delayed_15'] = np.zeros(len(ontime))\n",
    "ontime['cat_delayed_60'] = np.zeros(len(ontime))\n",
    "\n",
    "delayed_15['cat_ontime'] = np.zeros(len(delayed_15))\n",
    "delayed_15['cat_delayed_15'] = np.ones(len(delayed_15))\n",
    "delayed_15['cat_delayed_60'] = np.zeros(len(delayed_15))\n",
    "\n",
    "delayed_60['cat_ontime'] = np.zeros(len(delayed_60))\n",
    "delayed_60['cat_delayed_15'] = np.zeros(len(delayed_60))\n",
    "delayed_60['cat_delayed_60'] = np.ones(len(delayed_60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_training = pd.concat([ontime,delayed_15,delayed_60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_training = final_training.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_training.to_csv('Training_Data_Three_Categories.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Gathering weather information for training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import airportsdata as apd\n",
    "import meteostat as ms\n",
    "import pickle as pk\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/rk/815pd2rj3l5gyxnkn8q_m5sc0000gn/T/ipykernel_4331/2077803585.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfinal_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training_Data_Three_Categories.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "final_training = pd.read_csv('Training_Data_Three_Categories.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that all IATA airport codes in the training data map to one and only one ID number, since the codes are easier to look up but the instructions say they may have changed\n",
    "\n",
    "id_counts_by_IATA = {}\n",
    "count = 0\n",
    "all_codes = set(final_training.origin).union(set(final_training.dest))\n",
    "\n",
    "for code in all_codes:\n",
    "    count += 1\n",
    "    print(f'\\r{count} of {len(all_codes)}',end='')\n",
    "    id_codes = set(final_training[final_training.origin == code].origin_airport_id)\n",
    "    id_codes = id_codes.union(set(final_training[final_training.dest == code].dest_airport_id))\n",
    "    id_counts_by_IATA[code] = len(id_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that all id counts for all IATA codes are 1:\n",
    "\n",
    "set(id_counts_by_IATA.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load airport information indexed by 3-letter IATA codes\n",
    "airports = apd.load('IATA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to retrieve hourly and daily weather data for each airport, by IATA code, for 2018-01-01 to 2020-01-31\n",
    "\n",
    "def get_weather(airport,daily=True,hourly=True,start=datetime(2018,1,1,0),end=datetime(2020,1,31,23)):\n",
    "    if not (daily or hourly):\n",
    "        print('Neither daily nor hourly data requested; exiting.')\n",
    "        return\n",
    "    airport = airport_coordinates[airport]\n",
    "    airport = ms.Point(*airport)\n",
    "    airport.method = 'weighted'\n",
    "    airport.radius = 150000\n",
    "    airport.max_count = 25\n",
    "    airport.adapt_temp = False\n",
    "    if daily:\n",
    "        daily_data = ms.Daily(airport,start,end)\n",
    "        daily_data = daily_data.normalize()\n",
    "        daily_data = daily_data.interpolate(limit=10)\n",
    "        daily_data = daily_data.fetch()\n",
    "        daily_data = daily_data[['tavg','tmin','tmax','prcp','snow','wdir','wspd','pres']]\n",
    "    if hourly:\n",
    "        hourly_data = ms.Hourly(airport,start,end)\n",
    "        hourly_data = hourly_data.normalize()\n",
    "        hourly_data = hourly_data.interpolate(limit=48)\n",
    "        hourly_data = hourly_data.fetch()\n",
    "        hourly_data = hourly_data[['temp','rhum','prcp','wdir','wspd','pres']]\n",
    "    if daily and hourly:\n",
    "        return (daily_data, hourly_data)\n",
    "    else:\n",
    "        return daily_data if daily else hourly_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather(airport,daily=True,start=datetime(2018,1,1,0),end=datetime(2020,1,31,23)):\n",
    "    if not (daily or hourly):\n",
    "        print('Neither daily nor hourly data requested; exiting.')\n",
    "        return\n",
    "    airport = airport_coordinates[airport]\n",
    "    airport = ms.Point(*airport)\n",
    "    airport.method = 'weighted'\n",
    "    airport.radius = 150000\n",
    "    airport.max_count = 25\n",
    "    airport.adapt_temp = False\n",
    "    hourly = ms.Hourly(airport,start,end)\n",
    "    hourly_data = hourly.normalize()\n",
    "    hourly_data = hourly_data.interpolate(limit=48)\n",
    "    hourly_data = hourly_data.fetch()\n",
    "    if daily:\n",
    "        daily_data = hourly.normalize()\n",
    "        daily_data = daily_data.aggregate('1D')\n",
    "        daily_data = daily_data.fetch()\n",
    "    if daily and hourly:\n",
    "        return (daily_data, hourly_data)\n",
    "    else:\n",
    "        return daily_data if daily else hourly_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airport_coordinates = {}\n",
    "\n",
    "for code in all_codes:\n",
    "    if code not in airports:\n",
    "        while True:\n",
    "            coordinates = input(f'{code} not found; enter coordinates: ')\n",
    "            try:\n",
    "                lat, lon = coordinates.split(', ')\n",
    "                lat, lon = float(lat), float(lon)\n",
    "                break\n",
    "            except:\n",
    "                pass\n",
    "    else:\n",
    "        lat, lon = airports[code]['lat'], airports[code]['lon']\n",
    "    airport_coordinates[code] = (lat,lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Airport_Coordinates_Pickled_Data.pck','wb') as outfile:\n",
    "    pk.dump(airport_coordinates,outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Airport_Coordinates_Pickled_Data.pck','rb') as infile:\n",
    "    airport_coordinates = pk.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms.Hourly.clear_cache(max_age=0)\n",
    "ms.Daily.clear_cache(max_age=0)\n",
    "ms.Stations.clear_cache(max_age=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d,h = get_weather('SFO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.to_csv('TEST_SFO_AGG.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve weather data for every airport IATA code, and store in dicts, indexed by IATA codes\n",
    "\n",
    "all_codes = set(final_training.origin).union(set(final_training.dest))\n",
    "all_codes = sorted(list(all_codes))\n",
    "\n",
    "weather_hourly, weather_daily, failed_codes = {}, {}, []\n",
    "count = 0\n",
    "\n",
    "for code in all_codes:\n",
    "    count += 1\n",
    "    print(f'{count} of {len(all_codes)} ({code})')\n",
    "    \n",
    "    daily_exists = os.path.isfile(f'weather_data_daily/{code}.csv')\n",
    "    hourly_exists = os.path.isfile(f'weather_data_hourly/{code}.csv')\n",
    "    \n",
    "    if not daily_exists:\n",
    "        print(f'Getting daily for {code}')\n",
    "        try:\n",
    "            daily = get_weather(code,hourly=False)\n",
    "            if (len(daily) > 0) and ({ sum(daily[c].isna()) for c in daily.columns } == {0}):\n",
    "                print(f'\\n\\nSucceeded in getting new daily data for {code}')\n",
    "                daily.to_csv(f'weather_data_daily/{code}.csv')\n",
    "        except:\n",
    "            print('Exception')\n",
    "    \n",
    "    if not hourly_exists:\n",
    "        print(f'Getting hourly for {code}')\n",
    "        try:\n",
    "            hourly = get_weather(code,daily=False)\n",
    "            if (len(hourly) > 0) and ({ sum(hourly[c].isna()) for c in hourly.columns } == {0}):\n",
    "                print(f'\\n\\nSucceeded in getting new hourly data for {code}')\n",
    "                hourly.to_csv(f'weather_data_hourly/{code}.csv')\n",
    "        except:\n",
    "            print('Exception')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather data was gathered with scripts to based on the above cells to allow them to be run in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_training = pd.read_csv('Training_Data_Three_Categories.csv')\n",
    "final_training.loc[final_training.crs_arr_time == 1440,'crs_arr_time'] = 0\n",
    "# final_training.to_csv('Training_Data_Three_Categories.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WeatherData01/\n",
      "WeatherData02/\n",
      "WeatherData03/\n",
      "WeatherData04/\n",
      "WeatherData05/\n"
     ]
    }
   ],
   "source": [
    "weather_data = []\n",
    "\n",
    "for folder in ['WeatherData01/', 'WeatherData02/', 'WeatherData03/', 'WeatherData04/', 'WeatherData05/',]:\n",
    "    print(folder)\n",
    "    os.chdir(folder)\n",
    "    weather = {}\n",
    "    for fname in [ x for x in os.listdir(os.getcwd()) if 'hourly' in x ]:\n",
    "        code = fname.split('_')[0]\n",
    "        data = pd.read_csv(fname,index_col='time')\n",
    "        weather[code] = data\n",
    "    weather_data.append(weather)\n",
    "    os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_arr_time(row):\n",
    "    date_str = str(row.year) + str(row.julian)\n",
    "    arr_date = dt.datetime.strptime(date_str, '%Y%j')\n",
    "    t_dep = dt.time(row.crs_dep_time//60,row.crs_dep_time%60)\n",
    "    t_arr = dt.time(row.crs_arr_time//60,row.crs_arr_time%60)\n",
    "    arr_date = arr_date.replace(hour=t_arr.hour,minute=t_arr.minute)\n",
    "    if t_arr < t_dep:\n",
    "        arr_date += dt.timedelta(days=1)\n",
    "    return arr_date\n",
    "        \n",
    "def get_dep_time(row):\n",
    "    date_str = str(row.year) + str(row.julian)\n",
    "    dep_date = dt.datetime.strptime(date_str, '%Y%j')\n",
    "    t_dep = dt.time(row.crs_dep_time//60,row.crs_dep_time%60)\n",
    "    dep_date = dep_date.replace(hour=t_dep.hour,minute=t_dep.minute)\n",
    "    return dep_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_training = final_training.assign(arr_datetime = final_training.apply(get_arr_time,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_training = final_training.assign(dep_datetime = final_training.apply(get_dep_time,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_training = final_training.assign(arr_datetime_rounded = final_training.arr_datetime.dt.round('H'))\n",
    "final_training = final_training.assign(dep_datetime_rounded = final_training.dep_datetime.dt.round('H'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_training.loc[:,['dep_temp','dep_rhum','dep_prcp','dep_wdir','dep_wspd','dep_pres']] = np.nan\n",
    "final_training.loc[:,['arr_temp','arr_rhum','arr_prcp','arr_wdir','arr_wspd','arr_pres']] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_training = final_training[final_training.columns[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_training.to_csv('Training_Data_Three_Categories.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_training = pd.read_csv('Training_Data_Three_Categories.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dep_weather_data(df):\n",
    "    for i in range(len(df)):\n",
    "        if ((i+1) % 1000) == 0:\n",
    "            print(f'\\rProcessing row {(i+1)//1000}k')\n",
    "        dep_code, dep_dt = df.loc[i].origin, str(df.loc[i].dep_datetime_rounded)\n",
    "        dep_weather = weather_data[2][dep_code].loc[dep_dt]\n",
    "        arr_code, arr_dt = df.loc[i].dest, str(df.loc[i].arr_datetime_rounded)\n",
    "        arr_weather = weather_data[2][arr_code].loc[arr_dt]\n",
    "        df.loc[i,['dep_temp','dep_rhum','dep_prcp','dep_wdir','dep_wspd','dep_pres']] = list(dep_weather[['temp','rhum','prcp','wdir','wspd','pres']])\n",
    "        df.loc[i,['arr_temp','arr_rhum','arr_prcp','arr_wdir','arr_wspd','arr_pres']] = list(arr_weather[['temp','rhum','prcp','wdir','wspd','pres']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_training = pd.read_csv('Training_Data_Three_Categories.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in range(0,3000000,30000):\n",
    "    count += 1\n",
    "    subset = final_training.loc[i:i+29999]\n",
    "    subset.to_csv(f'Training_Data_Three_Categories_Part{count}.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [ pd.read_csv(x) for x in os.listdir(os.getcwd()) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000000"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>julian</th>\n",
       "      <th>mkt_unique_carrier</th>\n",
       "      <th>mkt_carrier_fl_num</th>\n",
       "      <th>op_unique_carrier</th>\n",
       "      <th>op_carrier_fl_num</th>\n",
       "      <th>origin_airport_id</th>\n",
       "      <th>origin</th>\n",
       "      <th>dest_airport_id</th>\n",
       "      <th>dest</th>\n",
       "      <th>...</th>\n",
       "      <th>dep_prcp</th>\n",
       "      <th>dep_wdir</th>\n",
       "      <th>dep_wspd</th>\n",
       "      <th>dep_pres</th>\n",
       "      <th>arr_temp</th>\n",
       "      <th>arr_rhum</th>\n",
       "      <th>arr_prcp</th>\n",
       "      <th>arr_wdir</th>\n",
       "      <th>arr_wspd</th>\n",
       "      <th>arr_pres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>63</td>\n",
       "      <td>DL</td>\n",
       "      <td>968</td>\n",
       "      <td>DL</td>\n",
       "      <td>968</td>\n",
       "      <td>14679</td>\n",
       "      <td>SAN</td>\n",
       "      <td>12478</td>\n",
       "      <td>JFK</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019</td>\n",
       "      <td>353</td>\n",
       "      <td>AA</td>\n",
       "      <td>1581</td>\n",
       "      <td>AA</td>\n",
       "      <td>1581</td>\n",
       "      <td>13303</td>\n",
       "      <td>MIA</td>\n",
       "      <td>15016</td>\n",
       "      <td>STL</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018</td>\n",
       "      <td>201</td>\n",
       "      <td>B6</td>\n",
       "      <td>106</td>\n",
       "      <td>B6</td>\n",
       "      <td>106</td>\n",
       "      <td>13930</td>\n",
       "      <td>ORD</td>\n",
       "      <td>12478</td>\n",
       "      <td>JFK</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019</td>\n",
       "      <td>53</td>\n",
       "      <td>WN</td>\n",
       "      <td>1272</td>\n",
       "      <td>WN</td>\n",
       "      <td>1272</td>\n",
       "      <td>14107</td>\n",
       "      <td>PHX</td>\n",
       "      <td>15016</td>\n",
       "      <td>STL</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>226</td>\n",
       "      <td>WN</td>\n",
       "      <td>1182</td>\n",
       "      <td>WN</td>\n",
       "      <td>1182</td>\n",
       "      <td>10140</td>\n",
       "      <td>ABQ</td>\n",
       "      <td>14107</td>\n",
       "      <td>PHX</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>2019</td>\n",
       "      <td>46</td>\n",
       "      <td>AS</td>\n",
       "      <td>2285</td>\n",
       "      <td>QX</td>\n",
       "      <td>2285</td>\n",
       "      <td>11648</td>\n",
       "      <td>FCA</td>\n",
       "      <td>14747</td>\n",
       "      <td>SEA</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>2019</td>\n",
       "      <td>266</td>\n",
       "      <td>WN</td>\n",
       "      <td>1965</td>\n",
       "      <td>WN</td>\n",
       "      <td>1965</td>\n",
       "      <td>14570</td>\n",
       "      <td>RNO</td>\n",
       "      <td>12889</td>\n",
       "      <td>LAS</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>2018</td>\n",
       "      <td>182</td>\n",
       "      <td>UA</td>\n",
       "      <td>738</td>\n",
       "      <td>UA</td>\n",
       "      <td>738</td>\n",
       "      <td>11292</td>\n",
       "      <td>DEN</td>\n",
       "      <td>13204</td>\n",
       "      <td>MCO</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>2019</td>\n",
       "      <td>57</td>\n",
       "      <td>AA</td>\n",
       "      <td>4785</td>\n",
       "      <td>PT</td>\n",
       "      <td>4785</td>\n",
       "      <td>14100</td>\n",
       "      <td>PHL</td>\n",
       "      <td>10581</td>\n",
       "      <td>BGR</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>2019</td>\n",
       "      <td>288</td>\n",
       "      <td>WN</td>\n",
       "      <td>4654</td>\n",
       "      <td>WN</td>\n",
       "      <td>4654</td>\n",
       "      <td>13204</td>\n",
       "      <td>MCO</td>\n",
       "      <td>13796</td>\n",
       "      <td>OAK</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000000 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       year  julian mkt_unique_carrier  mkt_carrier_fl_num op_unique_carrier  \\\n",
       "0      2018      63                 DL                 968                DL   \n",
       "1      2019     353                 AA                1581                AA   \n",
       "2      2018     201                 B6                 106                B6   \n",
       "3      2019      53                 WN                1272                WN   \n",
       "4      2019     226                 WN                1182                WN   \n",
       "...     ...     ...                ...                 ...               ...   \n",
       "29995  2019      46                 AS                2285                QX   \n",
       "29996  2019     266                 WN                1965                WN   \n",
       "29997  2018     182                 UA                 738                UA   \n",
       "29998  2019      57                 AA                4785                PT   \n",
       "29999  2019     288                 WN                4654                WN   \n",
       "\n",
       "       op_carrier_fl_num  origin_airport_id origin  dest_airport_id dest  ...  \\\n",
       "0                    968              14679    SAN            12478  JFK  ...   \n",
       "1                   1581              13303    MIA            15016  STL  ...   \n",
       "2                    106              13930    ORD            12478  JFK  ...   \n",
       "3                   1272              14107    PHX            15016  STL  ...   \n",
       "4                   1182              10140    ABQ            14107  PHX  ...   \n",
       "...                  ...                ...    ...              ...  ...  ...   \n",
       "29995               2285              11648    FCA            14747  SEA  ...   \n",
       "29996               1965              14570    RNO            12889  LAS  ...   \n",
       "29997                738              11292    DEN            13204  MCO  ...   \n",
       "29998               4785              14100    PHL            10581  BGR  ...   \n",
       "29999               4654              13204    MCO            13796  OAK  ...   \n",
       "\n",
       "       dep_prcp  dep_wdir  dep_wspd  dep_pres  arr_temp  arr_rhum  arr_prcp  \\\n",
       "0           NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "1           NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "2           NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "3           NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "4           NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "29995       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "29996       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "29997       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "29998       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "29999       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "       arr_wdir  arr_wspd  arr_pres  \n",
       "0           NaN       NaN       NaN  \n",
       "1           NaN       NaN       NaN  \n",
       "2           NaN       NaN       NaN  \n",
       "3           NaN       NaN       NaN  \n",
       "4           NaN       NaN       NaN  \n",
       "...         ...       ...       ...  \n",
       "29995       NaN       NaN       NaN  \n",
       "29996       NaN       NaN       NaN  \n",
       "29997       NaN       NaN       NaN  \n",
       "29998       NaN       NaN       NaN  \n",
       "29999       NaN       NaN       NaN  \n",
       "\n",
       "[3000000 rows x 40 columns]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>julian</th>\n",
       "      <th>mkt_unique_carrier</th>\n",
       "      <th>mkt_carrier_fl_num</th>\n",
       "      <th>op_unique_carrier</th>\n",
       "      <th>op_carrier_fl_num</th>\n",
       "      <th>origin_airport_id</th>\n",
       "      <th>origin</th>\n",
       "      <th>dest_airport_id</th>\n",
       "      <th>dest</th>\n",
       "      <th>...</th>\n",
       "      <th>dep_prcp</th>\n",
       "      <th>dep_wdir</th>\n",
       "      <th>dep_wspd</th>\n",
       "      <th>dep_pres</th>\n",
       "      <th>arr_temp</th>\n",
       "      <th>arr_rhum</th>\n",
       "      <th>arr_prcp</th>\n",
       "      <th>arr_wdir</th>\n",
       "      <th>arr_wspd</th>\n",
       "      <th>arr_pres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>63</td>\n",
       "      <td>DL</td>\n",
       "      <td>968</td>\n",
       "      <td>DL</td>\n",
       "      <td>968</td>\n",
       "      <td>14679</td>\n",
       "      <td>SAN</td>\n",
       "      <td>12478</td>\n",
       "      <td>JFK</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019</td>\n",
       "      <td>353</td>\n",
       "      <td>AA</td>\n",
       "      <td>1581</td>\n",
       "      <td>AA</td>\n",
       "      <td>1581</td>\n",
       "      <td>13303</td>\n",
       "      <td>MIA</td>\n",
       "      <td>15016</td>\n",
       "      <td>STL</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018</td>\n",
       "      <td>201</td>\n",
       "      <td>B6</td>\n",
       "      <td>106</td>\n",
       "      <td>B6</td>\n",
       "      <td>106</td>\n",
       "      <td>13930</td>\n",
       "      <td>ORD</td>\n",
       "      <td>12478</td>\n",
       "      <td>JFK</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019</td>\n",
       "      <td>53</td>\n",
       "      <td>WN</td>\n",
       "      <td>1272</td>\n",
       "      <td>WN</td>\n",
       "      <td>1272</td>\n",
       "      <td>14107</td>\n",
       "      <td>PHX</td>\n",
       "      <td>15016</td>\n",
       "      <td>STL</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>226</td>\n",
       "      <td>WN</td>\n",
       "      <td>1182</td>\n",
       "      <td>WN</td>\n",
       "      <td>1182</td>\n",
       "      <td>10140</td>\n",
       "      <td>ABQ</td>\n",
       "      <td>14107</td>\n",
       "      <td>PHX</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999995</th>\n",
       "      <td>2018</td>\n",
       "      <td>86</td>\n",
       "      <td>AA</td>\n",
       "      <td>2534</td>\n",
       "      <td>AA</td>\n",
       "      <td>2534</td>\n",
       "      <td>13342</td>\n",
       "      <td>MKE</td>\n",
       "      <td>11298</td>\n",
       "      <td>DFW</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999996</th>\n",
       "      <td>2018</td>\n",
       "      <td>205</td>\n",
       "      <td>DL</td>\n",
       "      <td>5106</td>\n",
       "      <td>9E</td>\n",
       "      <td>5106</td>\n",
       "      <td>12953</td>\n",
       "      <td>LGA</td>\n",
       "      <td>10785</td>\n",
       "      <td>BTV</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999997</th>\n",
       "      <td>2019</td>\n",
       "      <td>131</td>\n",
       "      <td>UA</td>\n",
       "      <td>4727</td>\n",
       "      <td>AX</td>\n",
       "      <td>4727</td>\n",
       "      <td>11292</td>\n",
       "      <td>DEN</td>\n",
       "      <td>13029</td>\n",
       "      <td>LNK</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999998</th>\n",
       "      <td>2019</td>\n",
       "      <td>164</td>\n",
       "      <td>WN</td>\n",
       "      <td>2132</td>\n",
       "      <td>WN</td>\n",
       "      <td>2132</td>\n",
       "      <td>11540</td>\n",
       "      <td>ELP</td>\n",
       "      <td>14107</td>\n",
       "      <td>PHX</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999999</th>\n",
       "      <td>2018</td>\n",
       "      <td>73</td>\n",
       "      <td>AA</td>\n",
       "      <td>3151</td>\n",
       "      <td>OO</td>\n",
       "      <td>3151</td>\n",
       "      <td>13930</td>\n",
       "      <td>ORD</td>\n",
       "      <td>11721</td>\n",
       "      <td>FNT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000000 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         year  julian mkt_unique_carrier  mkt_carrier_fl_num  \\\n",
       "0        2018      63                 DL                 968   \n",
       "1        2019     353                 AA                1581   \n",
       "2        2018     201                 B6                 106   \n",
       "3        2019      53                 WN                1272   \n",
       "4        2019     226                 WN                1182   \n",
       "...       ...     ...                ...                 ...   \n",
       "2999995  2018      86                 AA                2534   \n",
       "2999996  2018     205                 DL                5106   \n",
       "2999997  2019     131                 UA                4727   \n",
       "2999998  2019     164                 WN                2132   \n",
       "2999999  2018      73                 AA                3151   \n",
       "\n",
       "        op_unique_carrier  op_carrier_fl_num  origin_airport_id origin  \\\n",
       "0                      DL                968              14679    SAN   \n",
       "1                      AA               1581              13303    MIA   \n",
       "2                      B6                106              13930    ORD   \n",
       "3                      WN               1272              14107    PHX   \n",
       "4                      WN               1182              10140    ABQ   \n",
       "...                   ...                ...                ...    ...   \n",
       "2999995                AA               2534              13342    MKE   \n",
       "2999996                9E               5106              12953    LGA   \n",
       "2999997                AX               4727              11292    DEN   \n",
       "2999998                WN               2132              11540    ELP   \n",
       "2999999                OO               3151              13930    ORD   \n",
       "\n",
       "         dest_airport_id dest  ...  dep_prcp  dep_wdir  dep_wspd  dep_pres  \\\n",
       "0                  12478  JFK  ...       NaN       NaN       NaN       NaN   \n",
       "1                  15016  STL  ...       NaN       NaN       NaN       NaN   \n",
       "2                  12478  JFK  ...       NaN       NaN       NaN       NaN   \n",
       "3                  15016  STL  ...       NaN       NaN       NaN       NaN   \n",
       "4                  14107  PHX  ...       NaN       NaN       NaN       NaN   \n",
       "...                  ...  ...  ...       ...       ...       ...       ...   \n",
       "2999995            11298  DFW  ...       NaN       NaN       NaN       NaN   \n",
       "2999996            10785  BTV  ...       NaN       NaN       NaN       NaN   \n",
       "2999997            13029  LNK  ...       NaN       NaN       NaN       NaN   \n",
       "2999998            14107  PHX  ...       NaN       NaN       NaN       NaN   \n",
       "2999999            11721  FNT  ...       NaN       NaN       NaN       NaN   \n",
       "\n",
       "         arr_temp  arr_rhum  arr_prcp  arr_wdir  arr_wspd  arr_pres  \n",
       "0             NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "1             NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "2             NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "3             NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "4             NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "...           ...       ...       ...       ...       ...       ...  \n",
       "2999995       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "2999996       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "2999997       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "2999998       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "2999999       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "\n",
       "[3000000 rows x 40 columns]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sys import argv\n",
    "\n",
    "weather_data = []\n",
    "flight_data = pd.read_csv(argv[1])\n",
    "\n",
    "for folder in ['WeatherData01/', 'WeatherData02/', 'WeatherData03/', 'WeatherData04/', 'WeatherData05/',]:\n",
    "    os.chdir(folder)\n",
    "    weather = {}\n",
    "    for fname in [ x for x in os.listdir(os.getcwd()) if 'hourly' in x ]:\n",
    "        code = fname.split('_')[0]\n",
    "        data = pd.read_csv(fname,index_col='time')\n",
    "        weather[code] = data\n",
    "    weather_data.append(weather)\n",
    "    os.chdir('..')\n",
    "    \n",
    "def get_dep_weather_data(df):\n",
    "    for i in range(len(df)):\n",
    "        if ((i+1) % 1000) == 0:\n",
    "            print(f'\\rProcessing row {(i+1)//1000}k')\n",
    "        dep_code, dep_dt = df.loc[i].origin, str(df.loc[i].dep_datetime_rounded)\n",
    "        dep_weather = weather_data[2][dep_code].loc[dep_dt]\n",
    "        arr_code, arr_dt = df.loc[i].dest, str(df.loc[i].arr_datetime_rounded)\n",
    "        arr_weather = weather_data[2][arr_code].loc[arr_dt]\n",
    "        df.loc[i,['dep_temp','dep_rhum','dep_prcp','dep_wdir','dep_wspd','dep_pres']] = list(dep_weather[['temp','rhum','prcp','wdir','wspd','pres']])\n",
    "        df.loc[i,['arr_temp','arr_rhum','arr_prcp','arr_wdir','arr_wspd','arr_pres']] = list(arr_weather[['temp','rhum','prcp','wdir','wspd','pres']])\n",
    "\n",
    "get_dep_weather_data(flight_data)\n",
    "\n",
    "flight_data.to_csv(argv[1].replace('.csv','_with_weather.csv'),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
